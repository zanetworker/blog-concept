---
title: "Fine-Tuning LLMs: LoRA or Full-Parameter? An in-depth Analysis with Llama 2"
date: 2024-05-04
tags: ["ai","strategy","economics"]
type: link
linkUrl: "https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2"
linkTitle: "Fine-Tuning LLMs: LoRA or Full-Parameter? An in-depth Analysis with Llama 2"
sourceEntry: "pre-training-fine-tuning-and-kungfu.md"
sourceEntryTitle: "Pre-training, Fine-tuning, and Kungfu!"
---

_Extracted from: pre-training-fine-tuning-and-kungfu.md_
